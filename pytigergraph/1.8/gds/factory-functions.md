![TigerGraph Logo](https://www.tigergraph.com/wp-content/uploads/2020/05/TG_LOGO.svg) [Docs](https://docs.tigergraph.com/home)
Page 1[Prev](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions)[Next](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions)
Search by [Algolia](https://www.algolia.com/docsearch)
[Products](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions)
TigerGraph Savanna
[TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/) [(_TigerGraph Cloud Classic_)](https://docs.tigergraph.com/cloud/main/start/overview)
TigerGraph Server
[TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
TigerGraph Suite
[GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Insights](https://docs.tigergraph.com/insights/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web)
Query Languages
[GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql)
AI & Graph Intelligence
[Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/) [Hybrid Graph+Vector Search](https://docs.tigergraph.com/gsql-ref/current/vector/)
Connectors and APIs
[Data Connectors](https://docs.tigergraph.com/tigergraph-server/current/data-loading) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/) [JDBC Driver](https://github.com/tigergraph/ecosys/tree/master/tools/etl/tg-jdbc-driver)
Legacy Documentation
[ Legacy Documentation ](https://docs-legacy.tigergraph.com)
[Resources](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions)
[Developer Site](https://dev.tigergraph.com/) [Community Forum](https://community.tigergraph.com/) [Knowledge Base](https://tigergraph.freshdesk.com/support/solutions)
[Download](https://dl.tigergraph.com)
[ TG Savanna](https://savanna.tgcloud.io)
### [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
  *     * [Overview](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
  *     * [Getting Started](https://docs.tigergraph.com/pytigergraph/1.8/getting-started/)
      * [Installing pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/getting-started/install)
      * [Connecting to TigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/getting-started/connection)
      * [pyTigerGraph 101](https://docs.tigergraph.com/pytigergraph/1.8/getting-started/101)
  *     * [Core Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/)
      * [TigerGraphConnection](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/base)
      * [AsyncTigerGraphConnection](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/async_base)
      * [Authentication Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/auth)
      * [Vertex Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/vertex)
      * [Edge Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/edge)
      * [Query Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/query)
      * [UDT Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/udt)
      * [GSQL Interface](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/gsql)
      * [Loading Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/loading)
      * [Path Finding Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/path)
      * [Schema Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/schema)
      * [Utility Functions](https://docs.tigergraph.com/pytigergraph/1.8/core-functions/utils)
  *     * [GDS Functions](https://docs.tigergraph.com/pytigergraph/1.8/gds/)
      * [Factory Functions](https://docs.tigergraph.com/pytigergraph/1.8/gds/gds)
      * [Data Loaders](https://docs.tigergraph.com/pytigergraph/1.8/gds/dataloaders)
      * [Featurizer](https://docs.tigergraph.com/pytigergraph/1.8/gds/featurizer)
      * [Metrics](https://docs.tigergraph.com/pytigergraph/1.8/gds/metrics)
      * [Splitters](https://docs.tigergraph.com/pytigergraph/1.8/gds/splitters)
      * [Transforms](https://docs.tigergraph.com/pytigergraph/1.8/gds/transforms)
        * [PyTorch Geometric Transforms](https://docs.tigergraph.com/pytigergraph/1.8/gds/pyg_transforms)
        * [NodePiece Transforms](https://docs.tigergraph.com/pytigergraph/1.8/gds/nodepiece_transforms)
      * [Trainer](https://docs.tigergraph.com/pytigergraph/1.8/gds/trainer)
      * [Models](https://docs.tigergraph.com/pytigergraph/1.8/gds/models)
        * [GraphSAGE](https://docs.tigergraph.com/pytigergraph/1.8/gds/graphsage)
        * [NodePiece](https://docs.tigergraph.com/pytigergraph/1.8/gds/nodepiece)
  *     * [TigerGraph CoPilot](https://docs.tigergraph.com/pytigergraph/1.8/ai/copilot)
  *     * [Datasets](https://docs.tigergraph.com/pytigergraph/1.8/datasets/datasets)
      * [Dataset Object](https://docs.tigergraph.com/pytigergraph/1.8/datasets/datasets_object)
  *     * [Visualization](https://docs.tigergraph.com/pytigergraph/1.8/visualization/visualization)
  *     * [Object Oriented Schema](https://docs.tigergraph.com/pytigergraph/1.8/object_oriented_schema/schema-def)
  *     * [Contributing](https://docs.tigergraph.com/pytigergraph/1.8/contributing/)
  *     * [Release Notes](https://docs.tigergraph.com/pytigergraph/1.8/release-notes/)
      * [Legacy Version Documentation](https://docs.tigergraph.com/pytigergraph/1.8/release-notes/legacy-tg-versions)


pyTigerGraph 1.8
[Fully-Managed: Savanna](https://docs.tigergraph.com/savanna/main/overview/)
[Self-Managed: TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
[Install](https://docs.tigergraph.com/tigergraph-server/current/getting-started/) [Manage](https://docs.tigergraph.com/tigergraph-server/current/system-management/)
Tutorials & Guides
[GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/GSQL.md) [OpenCypher in GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/Cypher.md) [Hybrid Vector Search](https://github.com/tigergraph/ecosys/blob/master/tutorials/VectorSearch.md)
Reference Manuals
[GSQL](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql/) [Vector](https://docs.tigergraph.com/gsql-ref/current/vector/) [REST APIs](https://docs.tigergraph.com/tigergraph-server/current/api/) [Configuration Parameters](https://docs.tigergraph.com/tigergraph-server/current/reference/configuration-parameters)
Visual Tools
[Develop: GraphStudio](https://docs.tigergraph.com/gui/4.2/intro/) [Administer: Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Visualize: Insights](https://docs.tigergraph.com/insights/4.2/intro/)
AI & Data Science
[Graph Algorithms](https://docs.tigergraph.com/graph-ml/3.10/intro/) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraphX](https://github.com/tigergraph/ecosys/blob/master/tutorials/TigerGraphX.md) [ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/) [CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/tigergraph-server/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/tigergraph-server/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/tigergraph-server/3.6/intro/)
  * [GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gsql-ref/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gsql-ref/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gsql-ref/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gsql-ref/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gsql-ref/3.6/intro/intro)
  * [TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/)
  * [GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gui/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gui/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gui/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gui/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gui/3.6/graphstudio/overview)
  * [Insights](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/insights/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/insights/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/insights/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/insights/3.9/intro/)
  * [Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/)
    * [3.10](https://docs.tigergraph.com/graph-ml/3.10/intro/)
  * [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.8](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.7](https://docs.tigergraph.com/pytigergraph/1.7/intro/)
    * [1.6](https://docs.tigergraph.com/pytigergraph/1.6/intro/)
  * [TigerGraph ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
    * [1.4](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
  * [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/)
    * [3.9](https://docs.tigergraph.com/graphql/3.9/)
  * [TigerGraph CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
    * [main](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph Cloud Classic](https://docs.tigergraph.com/cloud/main/start/overview)


[](https://docs.tigergraph.com/home/)
  * [pyTigerGraph 1.8](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
  * [Factory Functions](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions)


[Edit this Page](https://github.com/tigergraph/pytigergraph-docs/edit/v1.8/modules/gds/pages/factory-functions.adoc)
### Contents
  * [neighborLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_neighborloader)
  * [edgeLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgeloader)
  * [vertexLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexloader)
  * [graphLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_graphloader)
  * [featurizer()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_featurizer)
  * [vertexSplitter()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexsplitter)
  * [edgeSplitter()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgesplitter)


# Factory Functions
### Contents
  * [neighborLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_neighborloader)
  * [edgeLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgeloader)
  * [vertexLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexloader)
  * [graphLoader()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_graphloader)
  * [featurizer()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_featurizer)
  * [vertexSplitter()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexsplitter)
  * [edgeSplitter()](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgesplitter)


Factory Functions are a special collection of functions that return an instance of a class.
All factory functions are methods of the `GDS` class. You can call a factory function after instantiating a TigerGraph Connection. For example:
```
conn = TigerGraphConnection(
  host="http://127.0.0.1",
  graphname="Cora",
  username="tigergraph",
  password="tigergraph",
  useCert=False
)
edge_loader = conn.gds.edgeLoader(
  num_batches=1,
  attributes=["time", "is_train"])
python![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

The object returned has access to instance methods of the class. You can find the reference for those classes on the following pages:
  * [Data loaders](https://docs.tigergraph.com/pytigergraph/current/gds/dataloaders)
  * [Featurizer](https://docs.tigergraph.com/pytigergraph/current/gds/featurizer)
  * [Metrics](https://docs.tigergraph.com/pytigergraph/current/gds/metrics)
  * [Splitters](https://docs.tigergraph.com/pytigergraph/current/gds/dataloaders)


If you are not sure how to configure the optional arguments related to Kafka, leave them blank. More detailed instructions on how to use them will be provided in a future release.   
---  
## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_neighborloader)neighborLoader()
`neighborLoader(v_in_feats: Union[list, dict] = None, v_out_labels: Union[list, dict] = None, v_extra_feats: Union[list, dict] = None, e_in_feats: Union[list, dict] = None, e_out_labels: Union[list, dict] = None, e_extra_feats: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, num_neighbors: int = 10, num_hops: int = 2, shuffle: bool = False, filter_by: str = None, output_format: str = "PyG", add_self_loop: bool = False, loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) → NeighborLoader`
Returns a `NeighborLoader` instance. A `NeighborLoader` instance performs neighbor sampling from all vertices in the graph in batches in the following manner:
  1. It chooses a specified number (`batch_size`) of vertices as seeds. The number of batches is the total number of vertices divided by the batch size.
     * If you specify the number of batches (`num_batches`) instead, `batch_size` is calculated by dividing the total number of vertices by the number of batches. If specify both parameters, `batch_size` takes priority.
  2. It picks a specified number (`num_neighbors`) of neighbors of each seed at random.
  3. It picks the same number of neighbors for each neighbor, and repeats this process until it finished performing a specified number of hops (`num_hops`).


This generates one subgraph. As you loop through this data loader, every vertex will at some point be chosen as a seed and you will get the subgraph expanded from the seeds. If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds.
When you initialize the loader on a graph for the first time, the initialization might take a minute as it installs the corresponding query to the database. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same graph again.   
---  
See [the ML Workbench tutorial notebook](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_neighborloader.ipynb) for examples.
#### Parameters:
  * `v_in_feats (list, optional)`: Vertex attributes to be used as input features. Only numeric and boolean attributes are allowed. The type of an attribute is automatically determined from the database schema. Defaults to None.
  * `v_out_labels (list, optional)`: Vertex attributes to be used as labels for prediction. Only numeric and boolean attributes are allowed. Defaults to None.
  * `v_extra_feats (list, optional)`: Other attributes to get such as indicators of train/test data. All types of attributes are allowed. Defaults to None.
  * `e_in_feats (list, optional)`: Edge attributes to be used as input features. Only numeric and boolean attributes are allowed. The type of an attribute is automatically determined from the database schema. Defaults to None.
  * `e_out_labels (list, optional)`: Edge attributes to be used as labels for prediction. Only numeric and boolean attributes are allowed. Defaults to None.
  * `e_extra_feats (list, optional)`: Other edge attributes to get such as indicators of train/test data. All types of attributes are allowed. Defaults to None.
  * `batch_size (int, optional)`: Number of vertices as seeds in each batch. Defaults to None.
  * `num_batches (int, optional)`: Number of batches to split the vertices into as seeds. If both `batch_size` and `num_batches` are provided, `batch_size` takes higher priority. Defaults to 1.
  * `num_neighbors (int, optional)`: Number of neighbors to sample for each vertex. Defaults to 10.
  * `num_hops (int, optional)`: Number of hops to traverse when sampling neighbors. Defaults to 2.
  * `shuffle (bool, optional)`: Whether to shuffle the vertices before loading data. Defaults to False.
  * `filter_by (str, optional)`: A boolean attribute used to indicate which vertices can be included as seeds. Defaults to None.
  * `output_format (str, optional)`: Format of the output data of the loader. Only "PyG", "DGL" and "dataframe" are supported. Defaults to "PyG".
  * `add_self_loop (bool, optional)`: Whether to add self-loops to the graph. Defaults to False.
  * `loader_id (str, optional)`: An identifier of the loader which can be any string. It is also used as the Kafka topic name. If `None`, a random string will be generated for it. Defaults to None.
  * `buffer_size (int, optional)`: Number of data batches to prefetch and store in memory. Defaults to 4.
  * `kafka_address (str, optional)`: Address of the kafka broker. Defaults to None.
  * `kafka_max_msg_size (int, optional)`: Maximum size of a Kafka message in bytes. Defaults to 104857600.
  * `kafka_num_partitions (int, optional)`: Number of partitions for the topic created by this loader. Defaults to 1.
  * `kafka_replica_factor (int, optional)`: Number of replications for the topic created by this loader. Defaults to 1.
  * `kafka_retention_ms (int, optional)`: Retention time for messages in the topic created by this loader in milliseconds. Defaults to 60000.
  * `kafka_auto_del_topic (bool, optional)`: Whether to delete the Kafka topic once the loader finishes pulling data. Defaults to True.
  * `kafka_address_consumer (str, optional)`: Address of the kafka broker that a consumer should use. Defaults to be the same as `kafkaAddress`.
  * `kafka_address_producer (str, optional)`: Address of the kafka broker that a producer should use. Defaults to be the same as `kafkaAddress`.
  * `timeout (int, optional)`: Timeout value for GSQL queries, in ms. Defaults to 300000.


## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgeloader)edgeLoader()
`edgeLoader(attributes: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "dataframe", loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) → EdgeLoader`
Returns an `EdgeLoader` instance. An `EdgeLoader` instance loads all edges in the graph in batches.
It divides all edges into `num_batches` and returns each batch separately. You can also specify the size of each batch, and the number of batched is calculated accordingly. If you provide both parameters, `batch_size` take priority. The boolean attribute provided to `filter_by` indicates which edges are included. If you need random batches, set `shuffle` to True.
When you initialize the loader on a graph for the first time, the initialization might take a minute as it installs the corresponding query to the database. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same graph again.   
---  
There are two ways to use the data loader.
  * It can be used as an iterable, which means you can loop through it to get every batch of data. If you load all edges at once (`num_batches=1`), there will be only one batch (of all the edges) in the iterator.
  * You can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator. If there are multiple batches of data to load, it returns the loader itself.


#### Parameters:
  * `attributes (list, optional)`: Edge attributes to be included. Defaults to None.
  * `batch_size (int, optional)`: Number of edges in each batch. Defaults to None.
  * `num_batches (int, optional)`: Number of batches to split the edges. Defaults to 1.
  * `shuffle (bool, optional)`: Whether to shuffle the edges before loading data. Defaults to False.
  * `filter_by (str, optional)`: A boolean attribute used to indicate which edges are included. Defaults to None.
  * `output_format (str, optional)`: Format of the output data of the loader. Only "dataframe" is supported. Defaults to "dataframe".
  * `loader_id (str, optional)`: An identifier of the loader which can be any string. It is also used as the Kafka topic name. If `None`, a random string will be generated for it. Defaults to None.
  * `buffer_size (int, optional)`: Number of data batches to prefetch and store in memory. Defaults to 4.
  * `kafka_address (str, optional)`: Address of the kafka broker. Defaults to None.
  * `kafka_max_msg_size (int, optional)`: Maximum size of a Kafka message in bytes. Defaults to 104857600.
  * `kafka_num_partitions (int, optional)`: Number of partitions for the topic created by this loader. Defaults to 1.
  * `kafka_replica_factor (int, optional)`: Number of replications for the topic created by this loader. Defaults to 1.
  * `kafka_retention_ms (int, optional)`: Retention time for messages in the topic created by this loader in milliseconds. Defaults to 60000.
  * `kafka_auto_del_topic (bool, optional)`: Whether to delete the Kafka topic once the loader finishes pulling data. Defaults to True.
  * `kafka_address_consumer (str, optional)`: Address of the kafka broker that a consumer should use. Defaults to be the same as `kafkaAddress`.
  * `kafka_address_producer (str, optional)`: Address of the kafka broker that a producer should use. Defaults to be the same as `kafkaAddress`.
  * `timeout (int, optional)`: Timeout value for GSQL queries, in ms. Defaults to 300000.


See [the ML Workbench edge loader tutorial notebook](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_edgeloader.ipynb) for examples.
## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexloader)vertexLoader()
`vertexLoader(attributes: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "dataframe", loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) → VertexLoader`
Returns a `VertexLoader` instance. A `VertexLoader` can load all vertices of a graph in batches.
It divides vertices into `num_batches` and returns each batch separately. The boolean attribute provided to `filter_by` indicates which vertices are included. If you need random batches, set `shuffle` to True.
When you initialize the loader on a graph for the first time, the initialization might take a minute as it installs the corresponding query to the database. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same graph again.   
---  
There are two ways to use the data loader:
  * It can be used as an iterable, which means you can loop through it to get every batch of data. If you load all vertices at once (`num_batches=1`), there will be only one batch (of all the vertices) in the iterator.
  * You can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader again.


#### Parameters:
  * `attributes (list, optional)`: Vertex attributes to be included. Defaults to None.
  * `batch_size (int, optional)`: Number of vertices in each batch. Defaults to None.
  * `num_batches (int, optional)`: Number of batches to split the vertices. Defaults to 1.
  * `shuffle (bool, optional)`: Whether to shuffle the vertices before loading data. Defaults to False.
  * `filter_by (str, optional)`: A boolean attribute used to indicate which vertices can be included. Defaults to None.
  * `output_format (str, optional)`: Format of the output data of the loader. Only "dataframe" is supported. Defaults to "dataframe".
  * `loader_id (str, optional)`: An identifier of the loader which can be any string. It is also used as the Kafka topic name. If `None`, a random string will be generated for it. Defaults to None.
  * `buffer_size (int, optional)`: Number of data batches to prefetch and store in memory. Defaults to 4.
  * `kafka_address (str, optional)`: Address of the kafka broker. Defaults to None.
  * `kafka_max_msg_size (int, optional)`: Maximum size of a Kafka message in bytes. Defaults to 104857600.
  * `kafka_num_partitions (int, optional)`: Number of partitions for the topic created by this loader. Defaults to 1.
  * `kafka_replica_factor (int, optional)`: Number of replications for the topic created by this loader. Defaults to 1.
  * `kafka_retention_ms (int, optional)`: Retention time for messages in the topic created by this loader in milliseconds. Defaults to 60000.
  * `kafka_auto_del_topic (bool, optional)`: Whether to delete the Kafka topic once the loader finishes pulling data. Defaults to True.
  * `kafka_address_consumer (str, optional)`: Address of the kafka broker that a consumer should use. Defaults to be the same as `kafkaAddress`.
  * `kafka_address_producer (str, optional)`: Address of the kafka broker that a producer should use. Defaults to be the same as `kafkaAddress`.
  * `timeout (int, optional)`: Timeout value for GSQL queries, in ms. Defaults to 300000.


See [the ML Workbench tutorial notebook](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_vertexloader.ipynb) for examples.
## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_graphloader)graphLoader()
`graphLoader(v_in_feats: Union[list, dict] = None, v_out_labels: Union[list, dict] = None, v_extra_feats: Union[list, dict] = None, e_in_feats: Union[list, dict] = None, e_out_labels: Union[list, dict] = None, e_extra_feats: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "PyG", add_self_loop: bool = False, loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) → GraphLoader`
Returns a `GraphLoader`instance. A `GraphLoader` instance loads all edges from the graph in batches, along with the vertices that are connected with each edge.
Different from NeighborLoader which produces connected subgraphs, this loader generates (random) batches of edges and vertices attached to those edges.
When you initialize the loader on a graph for the first time, the initialization might take a minute as it installs the corresponding query to the database. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same graph again.   
---  
There are two ways to use the data loader:
  * It can be used as an iterable, which means you can loop through it to get every batch of data. If you load all data at once (`num_batches=1`), there will be only one batch (of all the data) in the iterator.
  * You can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader itself.


#### Parameters:
  * `v_in_feats (list, optional)`: Vertex attributes to be used as input features. Only numeric and boolean attributes are allowed. The type of an attribute is automatically determined from the database schema. Defaults to None.
  * `v_out_labels (list, optional)`: Vertex attributes to be used as labels for prediction. Only numeric and boolean attributes are allowed. Defaults to None.
  * `v_extra_feats (list, optional)`: Other attributes to get such as indicators of train/test data. All types of attributes are allowed. Defaults to None.
  * `e_in_feats (list, optional)`: Edge attributes to be used as input features. Only numeric and boolean attributes are allowed. The type of an attribute is automatically determined from the database schema. Defaults to None.
  * `e_out_labels (list, optional)`: Edge attributes to be used as labels for prediction. Only numeric and boolean attributes are allowed. Defaults to None.
  * `e_extra_feats (list, optional)`: Other edge attributes to get such as indicators of train/test data. All types of attributes are allowed. Defaults to None.
  * `batch_size (int, optional)`: Number of edges in each batch. Defaults to None.
  * `num_batches (int, optional)`: Number of batches to split the edges. Defaults to 1.
  * `shuffle (bool, optional)`: Whether to shuffle the data before loading. Defaults to False.
  * `filter_by (str, optional)`: A boolean attribute used to indicate which edges can be included. Defaults to None.
  * `output_format (str, optional)`: Format of the output data of the loader. Only "PyG", "DGL" and "dataframe" are supported. Defaults to "dataframe".
  * `add_self_loop (bool, optional)`: Whether to add self-loops to the graph. Defaults to False.
  * `loader_id (str, optional)`: An identifier of the loader which can be any string. It is also used as the Kafka topic name. If `None`, a random string will be generated for it. Defaults to None.
  * `buffer_size (int, optional)`: Number of data batches to prefetch and store in memory. Defaults to 4.
  * `kafka_address (str, optional)`: Address of the kafka broker. Defaults to None.
  * `kafka_max_msg_size (int, optional)`: Maximum size of a Kafka message in bytes. Defaults to 104857600.
  * `kafka_num_partitions (int, optional)`: Number of partitions for the topic created by this loader. Defaults to 1.
  * `kafka_replica_factor (int, optional)`: Number of replications for the topic created by this loader. Defaults to 1.
  * `kafka_retention_ms (int, optional)`: Retention time for messages in the topic created by this loader in milliseconds. Defaults to 60000.
  * `kafka_auto_del_topic (bool, optional)`: Whether to delete the Kafka topic once the loader finishes pulling data. Defaults to True.
  * `kafka_address_consumer (str, optional)`: Address of the kafka broker that a consumer should use. Defaults to be the same as `kafkaAddress`.
  * `kafka_address_producer (str, optional)`: Address of the kafka broker that a producer should use. Defaults to be the same as `kafkaAddress`.
  * `timeout (int, optional)`: Timeout value for GSQL queries, in ms. Defaults to 300000.


See [the ML Workbench tutorial notebook for graph loaders](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_graphloader.ipynb) for examples.
## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_featurizer)featurizer()
`featurizer() → Featurizer`
Get a featurizer.
#### Returns:
Featurizer
## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_vertexsplitter)vertexSplitter()
`vertexSplitter(timeout: int = 600000)`
Get a vertex splitter that splits vertices into at most 3 parts randomly.
The split results are stored in the provided vertex attributes. Each boolean attribute indicates which part a vertex belongs to.
#### Usage:
  * A random 60% of vertices will have their attribute `attr_name` set to True, and others False. `attr_name` can be any attribute that exists in the database (same below). Example:


```
conn = TigerGraphConnection(...)
splitter = RandomVertexSplitter(conn, timeout, attr_name=0.6)
splitter.run()
```

  * A random 60% of vertices will have their attribute "attr_name" set to True, and a random 20% of vertices will have their attribute "attr_name2" set to True. The two parts are disjoint. Example:


```
conn = TigerGraphConnection(...)
splitter = RandomVertexSplitter(conn, timeout, attr_name=0.6, attr_name2=0.2)
splitter.run()
```

  * A random 60% of vertices will have their attribute "attr_name" set to True, a random 20% of vertices will have their attribute "attr_name2" set to True, and another random 20% of vertices will have their attribute "attr_name3" set to True. The three parts are disjoint. Example:


```
conn = TigerGraphConnection(...)
splitter = RandomVertexSplitter(conn, timeout, attr_name=0.6, attr_name2=0.2, attr_name3=0.2)
splitter.run()
```

#### Parameter:
  * `timeout (int, optional)`: Timeout value for the operation. Defaults to 600000.


## [](https://docs.tigergraph.com/pytigergraph/1.8/gds/factory-functions#_edgesplitter)edgeSplitter()
`edgeSplitter(timeout: int = 600000)`
Get an edge splitter that splits edges into at most 3 parts randomly.
The split results are stored in the provided edge attributes. Each boolean attribute indicates which part an edge belongs to.
#### Usage:
  * A random 60% of edges will have their attribute "attr_name" set to True, and others False. `attr_name` can be any attribute that exists in the database (same below). Example:
```
conn = TigerGraphConnection(...)
splitter = conn.gds.edgeSplitter(timeout, attr_name=0.6)
splitter.run()
python![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  * A random 60% of edges will have their attribute "attr_name" set to True, and a random 20% of edges will have their attribute "attr_name2" set to True. The two parts are disjoint. Example:
```
conn = TigerGraphConnection(...)
splitter = conn.gds.edgeSplitter(timeout, attr_name=0.6, attr_name2=0.2)
splitter.run()
python![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  * A random 60% of edges will have their attribute "attr_name" set to True, a random 20% of edges will have their attribute "attr_name2" set to True, and another random 20% of edges will have their attribute "attr_name3" set to True. The three parts are disjoint. Example:
```
conn = TigerGraphConnection(...)
splitter = conn.gds.edgeSplitter(timeout, attr_name=0.6, attr_name2=0.2, attr_name3=0.2)
splitter.run()
python![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```



#### Parameter:
timeout (int, optional): Timeout value for the operation. Defaults to 600000.
3 Twin Dolphin Drive, Ste 225 Redwood City, CA 94065 
Copyright © 2025 TigerGraph
  * ## Resources
    * [Support](https://www.tigergraph.com/support/)
    * [Community](https://community.tigergraph.com/)
    * [Developer Site](https://dev.tigergraph.com/)
    * [Test Drive](https://testdrive.tigergraph.com/)
  * ## Social
    * [Linkedin](https://www.linkedin.com/company/tigergraph/)
    * [Facebook](https://www.facebook.com/TigerGraphDB/)
    * [Twitter](https://twitter.com/tigergraphdb)
  * ## Legal
    * [Privacy Policy](https://www.tigergraph.com/privacy-policy/)
    * [Terms of Use](https://www.tigergraph.com/terms/)
    * [Sitemap](https://docs.tigergraph.com/sitemap.xml)


