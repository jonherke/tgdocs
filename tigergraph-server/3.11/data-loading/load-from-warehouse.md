![TigerGraph Logo](https://www.tigergraph.com/wp-content/uploads/2020/05/TG_LOGO.svg) [Docs](https://docs.tigergraph.com/home)
Page 1[Prev](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)[Next](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)
Search by [Algolia](https://www.algolia.com/docsearch)
[Products](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)
TigerGraph Savanna
[TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/) [(_TigerGraph Cloud Classic_)](https://docs.tigergraph.com/cloud/main/start/overview)
TigerGraph Server
[TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
TigerGraph Suite
[GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Insights](https://docs.tigergraph.com/insights/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web)
Query Languages
[GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql)
AI & Graph Intelligence
[Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/) [Hybrid Graph+Vector Search](https://docs.tigergraph.com/gsql-ref/current/vector/)
Connectors and APIs
[Data Connectors](https://docs.tigergraph.com/tigergraph-server/current/data-loading) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/) [JDBC Driver](https://github.com/tigergraph/ecosys/tree/master/tools/etl/tg-jdbc-driver)
Legacy Documentation
[ Legacy Documentation ](https://docs-legacy.tigergraph.com)
[Resources](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)
[Developer Site](https://dev.tigergraph.com/) [Community Forum](https://community.tigergraph.com/) [Knowledge Base](https://tigergraph.freshdesk.com/support/solutions)
[Download](https://dl.tigergraph.com)
[ TG Savanna](https://savanna.tgcloud.io)
### [TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
  *     * [TigerGraph DB Release Notes](https://docs.tigergraph.com/tigergraph-server/3.11/release-notes/)
  *     * [Overview](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
    * [Get Started](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/)
      * Installation
        * [On Docker](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/docker)
        * [On Kubernetes](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/kubernetes)
        * [On Cloud Marketplace](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/cloud-images/)
          * [AWS](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/cloud-images/aws)
          * [Azure](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/cloud-images/azure)
          * [GCP](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/cloud-images/gcp)
        * [On Linux](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/linux)
          * [System Requirements](https://docs.tigergraph.com/tigergraph-server/3.11/installation/hw-and-sw-requirements)
          * [Linux On Bare Metal](https://docs.tigergraph.com/tigergraph-server/3.11/installation/bare-metal-install)
          * [Post Install Checks](https://docs.tigergraph.com/tigergraph-server/3.11/installation/post-install-check)
        * [Advanced License Issues](https://docs.tigergraph.com/tigergraph-server/3.11/installation/license)
        * [Changing Ports](https://docs.tigergraph.com/tigergraph-server/3.11/installation/change-port)
        * [Upgrade](https://docs.tigergraph.com/tigergraph-server/3.11/installation/upgrade)
        * [Uninstallation](https://docs.tigergraph.com/tigergraph-server/3.11/installation/uninstallation)
      * [The GSQL Shell](https://docs.tigergraph.com/tigergraph-server/3.11/gsql-shell/)
        * [GSQL Shell Sessions](https://docs.tigergraph.com/tigergraph-server/3.11/gsql-shell/gsql-sessions)
        * [Using a Remote GSQL Client](https://docs.tigergraph.com/tigergraph-server/3.11/gsql-shell/using-a-remote-gsql-client)
        * [GSQL Shell (Web)](https://docs.tigergraph.com/tigergraph-server/3.11/gsql-shell/web)
    * [Create Database](https://docs.tigergraph.com/tigergraph-server/3.11/getting-started/database-definition)
      * [MultiGraph Overview](https://docs.tigergraph.com/tigergraph-server/3.11/intro/multigraph-overview)
  *     * [Load Data](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/)
      * [Overview](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/data-loading-overview)
      * [Externalize Kafka Configs](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/externalizing-kafka-configs)
      * [Load from Local Files](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-local-files)
      * [Load from Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-cloud)
      * [Load from Data Warehouse](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)
      * [Load from External Kafka](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-kafka)
        * [Avro Data Validation through KafkaConnect](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/avro-validation-with-kafka)
        * [Kafka SSL Security Guide](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/kafka-ssl-security-guide)
      * [Load from Spark Dataframe](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-spark-dataframe)
        * [Spark Connection Via JDBC Driver (Deprecated)](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/spark-connection-via-jdbc-driver)
      * [Manage Data Sources](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/manage-data-source)
      * [Data Loading V2](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/data-loading-v2)
      * [Stream from External Kafka (Deprecated)](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/data-streaming-connector/kafka)
  *     * Advanced Topics
      * [System Management](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/management-with-gadmin)
        * [Memory management](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/memory-management)
        * [Manage TigerGraph services](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/manage-services)
        * [Workload Management](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/workload-management)
        * [Metrics Reporting](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/system-metrics)
        * [Command Glossary](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/management-commands)
        * [Change Data Capture (CDC) Overview](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/change-data-capture/cdc-overview)
          * [CDC Setup](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/change-data-capture/cdc-setup)
          * [CDC Message Examples](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/change-data-capture/cdc-message-example)
          * [CDC State Monitoring](https://docs.tigergraph.com/tigergraph-server/3.11/system-management/change-data-capture/cdc-state-monitoring)
      * [Access Management](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/)
        * Authentication
          * [Enabling User Authentication](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/enabling-user-authentication)
          * [User Credentials](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/user-credentials)
          * [Single Sign-On](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/sso)
          * [Lightweight Directory Access Protocol (LDAP)](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/ldap)
          * [OIDC JWT Authentication](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/jwt-token)
        * Authorization
          * [User Management](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/user-management)
          * [Role Management](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/role-management)
          * [Access Control Model](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/access-control-model)
          * [Access Control Lists (ACLs)](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/acl-management)
          * [Row Policy Overview (Preview Feature)](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/rbac-row-policy/row-policy-overview)
            * [Key Concepts](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/rbac-row-policy/rbac-row-policy)
            * [Set Up Row Policy](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/rbac-row-policy/setup-row-policy)
          * [Vertex-Level Access Control (Deprecated)](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/vlac)
      * [Backup and Restore](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/)
        * [Database Import/Export All Graphs](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/database-import-export)
        * [Import/Export Individual Graphs](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/single-graph-import-export)
        * [Backup and Restore Configurations](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/configurations)
        * [Back up a Database Cluster](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/backup-cluster)
        * [Restore a Database Backup from the Same Cluster](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/restore-backup-same)
        * [Restore a Database Backup from Another Cluster](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/cross-cluster-backup)
        * [Differential Backup](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/differential-backups)
        * [Online Backup](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/online-backup)
        * [Legacy Backup and Restore](https://docs.tigergraph.com/tigergraph-server/3.11/backup-and-restore/gbar-legacy)
      * [Cluster and HA Management](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/)
        * Cluster Resizing
          * [Cluster Expansion](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/expand-a-cluster)
          * [Cluster Shrinking](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/shrink-a-cluster)
          * [Cluster Repartition](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/repartition-a-cluster)
          * [Cluster Replace](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/how_to-replace-a-node-in-a-cluster)
        * [Cross-Region Replication (CRR)](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/crr-index)
          * [Set up CRR](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/set-up-crr)
          * [Fail over to the DR cluster](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/fail-over)
          * [Troubleshooting CRR](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/troubleshooting)
          * [CRR FAQ](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/crr-faq)
        * [High Availability (HA)](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/ha-overview)
          * [Cluster Configuration](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/ha-cluster)
          * [GSQL Server Support](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/ha-for-gsql-server)
          * [Application Server Support](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/ha-for-application-server)
          * [Cluster Commands](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/cluster-commands)
          * [Removal of Failed Nodes](https://docs.tigergraph.com/tigergraph-server/3.11/cluster-and-ha-management/remove-failed-node)
      * [Architecture](https://docs.tigergraph.com/tigergraph-server/3.11/intro/internal-architecture)
        * [MultiGraph Overview](https://docs.tigergraph.com/tigergraph-server/3.11/intro/multigraph-overview)
        * [Transaction Processing and ACID Support](https://docs.tigergraph.com/tigergraph-server/3.11/intro/transaction-and-acid)
        * [Continuous Availability Overview](https://docs.tigergraph.com/tigergraph-server/3.11/intro/continuous-availability-overview)
      * [Kubernetes](https://docs.tigergraph.com/tigergraph-server/3.11/kubernetes/)
        * [Kubernetes Operator](https://docs.tigergraph.com/tigergraph-server/3.11/kubernetes/k8s-operator/)
  *     * [Security](https://docs.tigergraph.com/tigergraph-server/3.11/security/)
      * [Auditing Privileged User Actions](https://docs.tigergraph.com/tigergraph-server/3.11/security/audit-privileged-actions)
      * [Encrypting Connections](https://docs.tigergraph.com/tigergraph-server/3.11/security/encrypting-connections)
      * [Encrypting Data At Rest](https://docs.tigergraph.com/tigergraph-server/3.11/security/encrypting-data-at-rest)
      * [File Input Policy](https://docs.tigergraph.com/tigergraph-server/3.11/security/gsql-file-input-policy)
      * [File Output Policy](https://docs.tigergraph.com/tigergraph-server/3.11/security/file-output-policy)
      * [Login Policy](https://docs.tigergraph.com/tigergraph-server/3.11/security/login-protection)
      * [Password Policy](https://docs.tigergraph.com/tigergraph-server/3.11/security/password-policy)
  *     * [REST API Reference](https://docs.tigergraph.com/tigergraph-server/3.11/API/)
      * [Authentication](https://docs.tigergraph.com/tigergraph-server/3.11/API/authentication)
      * [Built-in Endpoints](https://docs.tigergraph.com/tigergraph-server/3.11/API/built-in-endpoints)
      * [Built-in Endpoints JSON Catalog](https://docs.tigergraph.com/tigergraph-server/3.11/API/json-catalog)
      * [Upsert data to graph](https://docs.tigergraph.com/tigergraph-server/3.11/API/upsert-rest)
  *     * Additional Resources
      * [Best Practices](https://docs.tigergraph.com/tigergraph-server/3.11/additional-resources/best-practice-guides/best-practices-overview)
        * [Scaling Guide](https://docs.tigergraph.com/tigergraph-server/3.11/additional-resources/best-practice-guides/best-prac-scaling-clusters)
      * Troubleshooting and FAQs
        * [Knowledge base and FAQs](https://kb.tigergraph.com/)
        * [Troubleshooting Guide](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/troubleshooting-guide)
        * [System Administration FAQs](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/system-administration-faqs)
        * [Log Files](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/log-files)
          * [Audit Logs](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/audit-log)
          * [Gathering Log Information with gcollect](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/gcollect)
          * [Set up Log Viewing with Elasticsearch, Kibana and Filebeat](https://docs.tigergraph.com/tigergraph-server/3.11/troubleshooting/elk-filebeat)
      * References
        * [Configuration Parameters](https://docs.tigergraph.com/tigergraph-server/3.11/reference/configuration-parameters)
        * [Return codes](https://docs.tigergraph.com/tigergraph-server/3.11/reference/return-codes)
        * [Object-Based Privilege Tables](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/rbac-row-policy/row-policy-privileges-table)
        * [List of Legacy Privilege Syntax](https://docs.tigergraph.com/tigergraph-server/3.11/reference/list-of-privileges)
        * [List of Ports](https://docs.tigergraph.com/tigergraph-server/3.11/reference/ports)
        * [Glossary](https://docs.tigergraph.com/tigergraph-server/3.11/reference/glossary)
        * [Patents and Third Party Software](https://docs.tigergraph.com/tigergraph-server/3.11/reference/patents-and-third-party-software)
        * [Legacy Version Documentation](https://docs.tigergraph.com/tigergraph-server/3.11/additional-resources/legacy-tg-versions)
        * [Comparing TigerGraph Editions](https://docs.tigergraph.com/tigergraph-server/3.11/intro/comparison-of-editions)
        * [Release and Patch Process](https://docs.tigergraph.com/tigergraph-server/3.11/intro/release-process)
        * [RBAC Row Policy EBNF](https://docs.tigergraph.com/tigergraph-server/3.11/user-access/rbac-row-policy/row-policy-ebnf)


TigerGraph DB 3.11
[Fully-Managed: Savanna](https://docs.tigergraph.com/savanna/main/overview/)
[Self-Managed: TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
[Install](https://docs.tigergraph.com/tigergraph-server/current/getting-started/) [Manage](https://docs.tigergraph.com/tigergraph-server/current/system-management/)
Tutorials & Guides
[GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/GSQL.md) [OpenCypher in GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/Cypher.md) [Hybrid Vector Search](https://github.com/tigergraph/ecosys/blob/master/tutorials/VectorSearch.md)
Reference Manuals
[GSQL](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql/) [Vector](https://docs.tigergraph.com/gsql-ref/current/vector/) [REST APIs](https://docs.tigergraph.com/tigergraph-server/current/api/) [Configuration Parameters](https://docs.tigergraph.com/tigergraph-server/current/reference/configuration-parameters)
Visual Tools
[Develop: GraphStudio](https://docs.tigergraph.com/gui/4.2/intro/) [Administer: Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Visualize: Insights](https://docs.tigergraph.com/insights/4.2/intro/)
AI & Data Science
[Graph Algorithms](https://docs.tigergraph.com/graph-ml/3.10/intro/) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraphX](https://github.com/tigergraph/ecosys/blob/master/tutorials/TigerGraphX.md) [ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/) [CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/tigergraph-server/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/tigergraph-server/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/tigergraph-server/3.6/intro/)
  * [GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gsql-ref/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gsql-ref/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gsql-ref/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gsql-ref/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gsql-ref/3.6/intro/intro)
  * [TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/)
  * [GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gui/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gui/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gui/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gui/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gui/3.6/graphstudio/overview)
  * [Insights](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/insights/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/insights/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/insights/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/insights/3.9/intro/)
  * [Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/)
    * [3.10](https://docs.tigergraph.com/graph-ml/3.10/intro/)
  * [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.8](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.7](https://docs.tigergraph.com/pytigergraph/1.7/intro/)
    * [1.6](https://docs.tigergraph.com/pytigergraph/1.6/intro/)
  * [TigerGraph ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
    * [1.4](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
  * [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/)
    * [3.9](https://docs.tigergraph.com/graphql/3.9/)
  * [TigerGraph CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
    * [main](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph Cloud Classic](https://docs.tigergraph.com/cloud/main/start/overview)


[](https://docs.tigergraph.com/home/)
  * [TigerGraph DB 3.11](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
  * [Load Data](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/)
  * [Load from Data Warehouse](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse)


[Edit this Page](https://github.com/tigergraph/server-docs/edit/3.11/modules/data-loading/pages/load-from-warehouse.adoc)
### Contents
  * [Example Schema](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_schema)
  * [Create Data Source Object](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_data_source_object)
  * [BigQuery](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_bigquery)
  * [Snowflake](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake)
  * [PostgreSql](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql)
  * [Create a loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_a_loading_job)
  * [Example loading job from a data warehouse](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_loading_job_from_a_data_warehouse)
  * [Define filenames](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_define_filenames)
  * [Specify the data mapping](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_specify_the_data_mapping)
  * [Run the loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_run_the_loading_job)
  * [Continuous Loading from Data Warehouses](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_continuous_loading_from_data_warehouses)
  * [Manage and monitor your loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_and_monitor_your_loading_job)
  * [Manage loading job concurrency](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_loading_job_concurrency)
  * [Known Issues with Loading](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_known_issues_with_loading)


# Load from a Data Warehouse
Table of Contents
  * [Example Schema](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_schema)
  * [Create Data Source Object](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_data_source_object)
    * [String Literals](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_string_literals)
    * [BigQuery](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_bigquery)
    * [Snowflake](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake)
    * [PostgreSql](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql)
  * [Create a loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_a_loading_job)
    * [Example loading job from a data warehouse](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_loading_job_from_a_data_warehouse)
      * [Big Query](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_big_query)
      * [Snowflake](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake_2)
      * [PostgreSql](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql_2)
    * [Define filenames](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_define_filenames)
      * [Data warehouse file descriptors](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_data_warehouse_file_descriptors)
      * [Filename parameters](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_filename_parameters)
    * [Specify the data mapping](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_specify_the_data_mapping)
      * [Data Mapping from BigQuery reuslts](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_data_mapping_from_bigquery_reuslts)
  * [Run the loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_run_the_loading_job)
    * [Continuous Loading from Data Warehouses](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_continuous_loading_from_data_warehouses)
  * [Manage and monitor your loading job](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_and_monitor_your_loading_job)
  * [Manage loading job concurrency](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_loading_job_concurrency)
  * [Known Issues with Loading](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_known_issues_with_loading)


After you have [defined a graph schema](https://docs.tigergraph.com/gsql-ref/3.11/ddl-and-loading/defining-a-graph-schema), you can create a loading job, specify your data sources, and run the job to load data.
The steps for loading from local files, cloud storage, or any other supported sources are similar. We will call out whether a particular step is common for all loading or specific to a data source or loading mode.
## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_schema)Example Schema
Example schema taken from LDBC_SNB
```
//Vertex Types:
CREATE VERTEX Person(PRIMARY_ID id UINT, firstName STRING, lastName STRING,
 gender STRING, birthday DATETIME, creationDate DATETIME, locationIP STRING,
 browserUsed STRING, speaks SET<STRING>, email SET<STRING>)
 WITH STATS="OUTDEGREE_BY_EDGETYPE", PRIMARY_ID_AS_ATTRIBUTE="true"
CREATE VERTEX Comment(PRIMARY_ID id UINT, creationDate DATETIME,
 locationIP STRING, browserUsed STRING, content STRING, length UINT)
 WITH STATS="OUTDEGREE_BY_EDGETYPE", PRIMARY_ID_AS_ATTRIBUTE="true"
//Edge Types:
CREATE DIRECTED EDGE HAS_CREATOR(FROM Comment, TO Person)
 WITH REVERSE_EDGE="HAS_CREATOR_REVERSE"
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_data_source_object)Create Data Source Object
A data source object provides a standard interface for all supported data source types, so that loading jobs can be written without regard for the data source.
When you create the object, you specify its details (type, access credentials, etc.) in the form of a JSON object. The JSON object can either be read in from a file or provided inline.
Inline mode is required when creating data sources for TigerGraph Cloud instances.  
---  
In the following example, we create a data source named `s1`, and read its configuration information from a file called `ds_config.json`.
```
USE GRAPH ldbc_snb
CREATE DATA_SOURCE s1 = "ds_config.json" FOR GRAPH ldbc_snb
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Older versions of TigerGraph required a keyword after `DATA_SOURCE` such as `STREAM` or `KAFKA`.  
---  
Inline JSON data format when creating a data source
```
CREATE DATA_SOURCE s1 = "{
type: <type>,
key: <value>
}" FOR GRAPH ldbc_snb
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_string_literals)String Literals
String literals can be represented according to the following options:
  * Enclosed with double quote `"`.
  * Enclosed with triple double quotes `"""`.
  * Enclosed with triple single quotes `'''`.


In the case of JSON that does not contain a colon `:` or a comma `,` the double quotes `"` can be omitted.
Alternate quote syntax for inline JSON data
```
CREATE DATA_SOURCE s1 = """{
"type": "<type>",
"key": "<value>"
}""" FOR GRAPH ldbc_snb
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Either a period `.` or `_` can be used for separation in the specified key name. Example: `first.second` or `first_second`.
We currently support [BigQuery](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#BigQuery), [Snowflake](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake), and [PostgreSql](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql) data warehouses. More data warehouses will be supported in future releases.   
---  
### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_bigquery)BigQuery
TigerGraph’s BigQuery loader makes use of the [BigQuery JDBC connector provided by Google](https://cloud.google.com/bigquery/docs/reference/odbc-jdbc-drivers), in collaboration with Simba. Use the following configuration for the `DATA_SOURCE`.
Data source configuration for BigQuery
```
{
 "type":"bigquery",
 "ProjectId":"tigergraph-dev",
 "OAuthType":2,
 "parameters" : {
  "OAuthRefreshToken":"<refresh token>",
  "OAuthClientId":"<client ID>.apps.googleusercontent.com",
  "OAuthClientSecret":"<client secret>"
  #other Simba JDBC parameters
 }
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

In addition, for large query results, we highly recommended specifying the following parameters:   
---  
Addition parameter setting for large BigQuery results
```
"EnableHighThroughputAPI":"1" -> Storage Read API
"AllowLargeResults":"1" -> Large Query Result Support
"LargeResultDataset":"<target_dataset>" -> Storage for Temp Result
"LargeResultsDatasetExpirationTime":"<time_ms>" -> Expiration of Temp Result
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For more information about Simba/Google BigQuery JDBC connection parameters, please refer the [BigQuery JDBC Installation and Configuration Guide](https://cloud.google.com/bigquery/docs/reference/odbc-jdbc-drivers).
### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake)Snowflake
Data source configuration for Snowflake:
```
{
  "type":"snowflake",
  "connection.url":"jdbc:snowflake://https://<account_id>.snowflakecomputing.com/?db=<db>&schema=<schema>&role=<role>",
  "connection.user": "<username>",
  "connection.password": "<password>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Alternately, key-pair authentication can be used. See Snowflake’s document for more details on their support for [key-pair authentication and rotation](https://docs.snowflake.com/en/user-guide/key-pair-auth).
Data source configuration with key-pair authentication:
```
{
  "type":"snowflake",
  "connection.url":"jdbc:snowflake://https://<account_id>.snowflakecomputing.com/?db=<db>&schema=<schema>&role=<role>&private_key_file=<key_file>",
  "connection.user": "<userwithrsa>",
  "connection.password": "<anystring>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  * We recommend using the latest version of OpenSSL (3.0.11 19 Sep 2023) to generate keys.
  * When a private key is used, `connection.password` is still required, but it can be set to any non-empty string.
  * Passing a private key directly or using a private key file with a password is NOT supported.

  
---  
For Snowflake loading jobs only the default setting for `batch.max.rows` is set to `100000` for better performance.  
---  
Use the required fields below for a Snowflake data `DATA_SOURCE`:
Table 1. Required fields for Snowflake `DATA_SOURCE` Field | Example | Notes  
---|---|---  
`connection.url | `"jdbc:snowflake://https:// <account_id>.snowflakecomputing.com/?db=<db>&schema=<schema>&role=<role>",` | It should start with `jdbc:snowflake:`  
connection.user | "tigergraph"  
connection.password | "password" | This will be masked and shown as `******`  
type | "snowflake" | This must be `snowflake`.  
### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql)PostgreSql
Data source configuration for PostgreSql:
```
{
  "type":"postgresql",
  "host":"pg_address",
  "port": 5432,
  "connection.user":"postgres",
  "connection.password":"postgres",
  "db.name":"postgres"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

These are some required and optional configuration parameters for connection and authentication with a PostgreSql data `DATA_SOURCE`.
Table 2. Fields for PostgreSql `DATA_SOURCE` Field | Example | Notes  
---|---|---  
host | "postgresql_server_address" | The PostgreSql server’s address. This is **required**.  
port | "5432" | The port used by the PostgreSql server. The default is set to `5432`.  
connection.user | "DBuser" | The user of the PostgreSql server. This is **required**  
connection.password | "MyPassword" | The password of the user. This is **required**  
db.name | "postgres" | The database name. This is **required**  
## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_create_a_loading_job)Create a loading job
A loading job tells the database how to construct vertices and edges from data sources. The loading job body has two parts:
  1. DEFINE statements create variables to refer to data sources. These can refer to actual files or be placeholder names. The actual data sources can be given when running the loading job.
  2. LOAD statements specify how to take the data fields from files to construct vertices or edges.


### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_example_loading_job_from_a_data_warehouse)Example loading job from a data warehouse
If single quote characters ( `'` ) need to be included in the query in bash, use ( `"'"` ) to escape. If double quotes are needed, use the JSON format for a query instead.  
---  
#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_big_query)Big Query
The following is an example loading job from Google BigQuery.
Example loading job for BigQuery
```
CREATE DATA_SOURCE s1 = """{
  "type":"bigquery",
  "ProjectId":"tigergraph-dev",
  "OAuthType":2,
  "parameters" : {
    "OAuthRefreshToken":"<refresh token>",
    "OAuthClientId":"<client ID>.apps.googleusercontent.com",
    "OAuthClientSecret":"<client secret>"
  }
}""" FOR GRAPH ldbc_snb
USE GRAPH ldbc_snb
CREATE LOADING JOB load_data FOR GRAPH ldbc_snb {
DEFINE FILENAME file_Comment =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment";
DEFINE FILENAME file_Person =
 "$s1:SELECT id, firstName, lastName, gender, birthday, creationDate, locationIP, browserUsed, language, email FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Person";
DEFINE FILENAME file_Comment_hasCreator_Person =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment_hasCreator_Person";
LOAD file_Comment
 TO VERTEX Comment
  VALUES ($1, $0, $2, $3, $4, $5)
  USING separator="|";
LOAD file_Person
 TO VERTEX Person
  VALUES ($1, $2, $3, $4, $5, $0, $6, $7, SPLIT($8,";"), SPLIT($9,";"))
  USING separator="|";
LOAD file_Comment_hasCreator_Person
 TO EDGE HAS_CREATOR
  VALUES ($1, $2) USING separator="|";
}
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_snowflake_2)Snowflake
The following is an example loading job from Snowflake.
Example loading job for Snowflake
```
CREATE DATA_SOURCE s1= """{
  "type":"snowflake",
  "connection.url": "jdbc:snowflake:/https:/<account_id>.snowflakecomputing.com/?db=<db>&schema=<schema>&role=<role>",
  "connection.user": "<username>",
  "connection.password": "<password>"
}""" FOR GRAPH ldbc_snb
USE GRAPH ldbc_snb
CREATE LOADING JOB load_data FOR GRAPH ldbc_snb {
DEFINE FILENAME file_Comment =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment";
DEFINE FILENAME file_Person =
 "$s1:SELECT id, firstName, lastName, gender, birthday, creationDate, locationIP, browserUsed, language, email FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Person";
DEFINE FILENAME file_Comment_hasCreator_Person =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment_hasCreator_Person";
LOAD file_Comment
 TO VERTEX Comment
  VALUES ($1, $0, $2, $3, $4, $5)
  USING separator="|";
LOAD file_Person
 TO VERTEX Person
  VALUES ($1, $2, $3, $4, $5, $0, $6, $7, SPLIT($8,";"), SPLIT($9,";"))
  USING separator="|";
LOAD file_Comment_hasCreator_Person
 TO EDGE HAS_CREATOR
  VALUES ($1, $2) USING separator="|";
}
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_postgresql_2)PostgreSql
The following is an example loading job from PostgreSql.
Example loading job for PostgreSql
```
CREATE DATA_SOURCE s1 = """{
  "type":"postgresql",
  "host":"pg_address",
  "port":5432,
  "connection.user":"postgres",
  "connection.password":"postgres",
  "db.name":"postgres"
}""" FOR GRAPH ldbc_snb
CREATE LOADING JOB load_data FOR GRAPH ldbc_snb {
DEFINE FILENAME file_Comment =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment";
DEFINE FILENAME file_Person =
 "$s1:SELECT id, firstName, lastName, gender, birthday, creationDate, locationIP, browserUsed, language, email FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Person";
DEFINE FILENAME file_Comment_hasCreator_Person =
 "$s1:SELECT * FROM tigergraph-ldbc-benchmark.snb_bi_sf01.Comment_hasCreator_Person";
LOAD file_Comment
 TO VERTEX Comment
  VALUES ($1, $0, $2, $3, $4, $5)
  USING separator="|";
LOAD file_Person
 TO VERTEX Person
  VALUES ($1, $2, $3, $4, $5, $0, $6, $7, SPLIT($8,";"), SPLIT($9,";"))
  USING separator="|";
LOAD file_Comment_hasCreator_Person
 TO EDGE HAS_CREATOR
  VALUES ($1, $2) USING separator="|";
}
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_define_filenames)Define filenames
First we define _filenames_ , which are local variables referring to data files (or data objects).
The terms `FILENAME` and `filevar` are used for legacy reasons, but a `filevar` can also be an object in a data object store.   
---  
DEFINE FILENAME syntax
```
DEFINE FILENAME filevar ["=" file_descriptor ];
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

The file descriptor can be specified at compile-time or at runtime. Runtime settings override compile-time settings:
Specifying file descriptor at runtime
```
RUN LOADING JOB job_name USING filevar=file_descriptor_override
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

While a loading job may have multiple `FILENAME` variables , they must all refer to the same `DATA_SOURCE` object.   
---  
#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_data_warehouse_file_descriptors)Data warehouse file descriptors
For data warehouses, you run a SQL query to get the data. The file descriptor has three valid formats. You can simply provide the SQL query statement. Or, you can provide optional configuration details, either in a JSON file or as inline JSON content.
```
DEFINE FILENAME file_name = "$[data source name]:[SQL]";
DEFINE FILENAME file_name = "$[data source name]:[json config file]";
DEFINE FILENAME file_name = "$[data source name]:[inline json content]";
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For example:
```
// Format 1: SQL query statement
DEFINE FILENAME query_person = "$s1:SELECT id,name,gender FROM ldbc.person";
// Format 2: Configuration file
DEFINE FILENAME bq_inline_json = """$s1:myfile.json""";
// Format 3: Inline JSON
DEFINE FILENAME query_person="""$s1:{
 "query": "SELECT id,name,gender
      FROM ldbc.person where age < 10;
      SELECT id,name,gender
      FROM ldbc.person where age > 50",
 "num.partitions": 6,
 "tasks.max": 2
}""";
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_filename_parameters)Filename parameters
These are the required and optional configuration parameters:
Parameter | Description | Required? | Default value  
---|---|---|---  
query | One or more SQL queries separated by commas. To avoid timeout in a large query, you can break it into multiple smaller queries based on the partitioning key. These queries may be assigned to multiple tasks for execution, while the execution order is not guaranteed. | Required | N/A  
batch.max.rows | Maximum number of rows to include in a single batch when polling for new data from the query result. | Optional | 1000 For Snowflake loading jobs only: The default setting for `batch.max.rows` is set to `100000` for better performance.  
num.partitions | The number of partitions to use. When loading data, each partition is distributed evenly across each node. If one filename contains much more data than others, consider using a larger partition number. | Optional | 3  
tasks.max | The maximum number of tasks used to execute queries. When `query` contains multiple queries, you can increase this parameter to execute queries in parallel. | Optional | 1  
poll.interval.ms | Time interval in ms for periodic executoion of the query. | Optional | 5000  
### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_specify_the_data_mapping)Specify the data mapping
Next, we use LOAD statements to describe how the incoming data will be loaded to attributes of vertices and edges. Each LOAD statement handles the data mapping, and optional data transformation and filtering, from one filename to one or more vertex and edge types.
LOAD statement syntax
```
LOAD [ source_object|filevar|TEMP_TABLE table_name ]
 destination_clause [, destination_clause ]*
 [ TAGS clause ] **(1)**
 [ USING clause ];
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

**1** | As of v3.9.3, TAGS are deprecated.  
---|---  
Let’s break down one of the LOAD statements in our example:
Example loading job for local files
```
LOAD file_Person TO VERTEX Person
  VALUES($1, $2, $3, $4, $5, $0, $6, $7,
    SPLIT($8, ";"), SPLIT($9, ";"))
  USING SEPARATOR="|", HEADER="true", EOL="\n";
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  * `$0`, `$1`,…​ refer to the first, second, …​ columns in each line a data file.
  * `SEPARATOR="|"` says the column separator character is the pipe (`|`). The default is comma (`,`).
  * `HEADER="true"` says that the first line in the source contains column header names instead of data. These names can be used instead of the columnn numbers.
  * `SPLIT` is one of GSQL’s ETL functions. It says that there is a multi-valued column, which has a separator character to mark the subfields in that column.


Refer to [Creating a Loading Job](https://docs.tigergraph.com/gsql-ref/3.11/ddl-and-loading/creating-a-loading-job) in the GSQL Language Reference for descriptions of all the options for loading jobs.
#### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_data_mapping_from_bigquery_reuslts)Data Mapping from BigQuery reuslts
The columns of SQL results are joined by a specified separator to form delimited content.
```
LOAD bq_sql TO VERTEX Comment VALUES ($1, $0, $2, $3, $4, $5) USING separator="|";
gsql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

In order to load nested or repeated records from BigQuery, some conversion functions need to be applied to the SQL statement.
**Querying STRUCT Data**
  * Method 1:
    1. Apply the BigQuery `TO_JSON_STRING` function to the columns of the STRUCT, e.g.,
```
SELECT TO_JSON_STRING(col) FROM table
sql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

    2. Flatten the JSON object to CSV format.
  * Method 2:
    * Retrieve the fields from the STRUCT directly, e.g.,
```
SELECT col.field1, col.field2, col.field3 FROM table
sql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```



**Querying Arrays**
  1. Apply function `ARRAY_TO_STRING` to the columns of `ARRAY` type, e.g.,
```
SELECT ARRAY_TO_STRING(col_arr,separator) FROM table
sql![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  2. In the LOAD statement, use the GSQL [SPLIT function](https://docs.tigergraph.com/gsql-ref/3.11/ddl-and-loading/functions/token/split).


## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_run_the_loading_job)Run the loading job
Use the command `RUN LOADING JOB` to run the loading job.
RUN LOADING JOB basic syntax (some options omitted)
```
RUN LOADING JOB [-noprint] job_name [
 USING filevar [="file_descriptor"][, filevar [="file_descriptor"]]*
 [,EOF="eof_mode"]
]
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

**-noprint**
By default, the loading job will run in the foreground and print the loading status and statistics after you submit the job. If the `-noprint` option is specified, the job will run in the background after displaying the job ID and the location of the log file.
**filevar list**
The optional `USING` clause may contain a list of file variables. Each file variable may optionally be assigned a `file_descriptor`, obeying the same format as in `CREATE LOADING JOB`. This list of file variables determines which parts of a loading job are run and what data files are used.
When a loading job is compiled, it generates one RESTPP endpoint for each `filevar` and source_object. As a consequence, a loading job can be run in parts. When `RUN LOADING JOB` is executed, only those endpoints whose filevar or file identifier (`_GSQL_FILENAME_n_`) is mentioned in the`USING` clause will be used. However, if the `USING` clause is omitted, then the entire loading job will be run.
If a `file_descriptor` is given, it overrides the `file_descriptor` defined in the loading job. If a particular `filevar` is not assigned a `file_descriptor` either in the loading job or in the `RUN LOADING JOB` statement, an error is reported and the job exits.
### [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_continuous_loading_from_data_warehouses)Continuous Loading from Data Warehouses
If `EOF="true"` (the default), then the query is executed once, and its output will be loaded.
If `EOF="false"`, the query will be executed periodically every `poll.interval.ms` and its output loaded. This will continuous indefinitely until the job is aborted.
Prior to version 3.9.2, the default value of `EOF` was "False". Beginning with 3.9.2, the default value is "True".
## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_and_monitor_your_loading_job)Manage and monitor your loading job
When a loading job starts, the GSQL server assigns it a job ID and displays it for the user to see. There are four key commands to monitor and manage loading jobs:
```
SHOW LOADING STATUS job_id|ALL
ABORT LOADING JOB job_id|ALL
RESUME LOADING JOB job_id
SHOW LOADING ERROR job_id
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

`SHOW LOADING STATUS` shows the current status of either a specified loading job or all current jobs, this command should be within the scope of a graph:
```
GSQL > USE GRAPH graph_name
GSQL > SHOW LOADING STATUS ALL
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For each loading job, the above command reports the following information:
  * Loading status
  * Loaded lines/Loaded objects/Error lines
  * Average loading speed
  * Size of loaded data
  * Duration


When inspecting all current jobs with `SHOW LOADING STATUS ALL`, the jobs in the `FINISHED` state will be omitted as they are considered to have successfully finished. You can use `SHOW LOADING STATUS job_id` to check the historical information of finished jobs. If the report for this job contains error data, you can use `SHOW LOADING ERROR job_id` to see the original data that caused the error.
See [Managing and Inspecting a Loading Job](https://docs.tigergraph.com/gsql-ref/3.11/ddl-and-loading/managing-loading-job) for more details.
## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_manage_loading_job_concurrency)Manage loading job concurrency
See [Loading Job Concurrency](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/loading-concurrency) for how to manage the concurrency of loading jobs.
## [](https://docs.tigergraph.com/tigergraph-server/3.11/data-loading/load-from-warehouse#_known_issues_with_loading)Known Issues with Loading
TigerGraph does not store NULL values. Therefore, your input data should not contain any NULLs.   
---  
3 Twin Dolphin Drive, Ste 225 Redwood City, CA 94065 
Copyright © 2025 TigerGraph
  * ## Resources
    * [Support](https://www.tigergraph.com/support/)
    * [Community](https://community.tigergraph.com/)
    * [Developer Site](https://dev.tigergraph.com/)
    * [Test Drive](https://testdrive.tigergraph.com/)
  * ## Social
    * [Linkedin](https://www.linkedin.com/company/tigergraph/)
    * [Facebook](https://www.facebook.com/TigerGraphDB/)
    * [Twitter](https://twitter.com/tigergraphdb)
  * ## Legal
    * [Privacy Policy](https://www.tigergraph.com/privacy-policy/)
    * [Terms of Use](https://www.tigergraph.com/terms/)
    * [Sitemap](https://docs.tigergraph.com/sitemap.xml)


