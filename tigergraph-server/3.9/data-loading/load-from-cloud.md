![TigerGraph Logo](https://www.tigergraph.com/wp-content/uploads/2020/05/TG_LOGO.svg) [Docs](https://docs.tigergraph.com/home)
Page 1[Prev](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)[Next](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)
Search by [Algolia](https://www.algolia.com/docsearch)
[Products](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)
TigerGraph Savanna
[TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/) [(_TigerGraph Cloud Classic_)](https://docs.tigergraph.com/cloud/main/start/overview)
TigerGraph Server
[TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
TigerGraph Suite
[GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Insights](https://docs.tigergraph.com/insights/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web)
Query Languages
[GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [GSQL Web Shell](https://docs.tigergraph.com/tigergraph-server/current/gsql-shell/web) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql)
AI & Graph Intelligence
[Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/) [Hybrid Graph+Vector Search](https://docs.tigergraph.com/gsql-ref/current/vector/)
Connectors and APIs
[Data Connectors](https://docs.tigergraph.com/tigergraph-server/current/data-loading) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/) [JDBC Driver](https://github.com/tigergraph/ecosys/tree/master/tools/etl/tg-jdbc-driver)
Legacy Documentation
[ Legacy Documentation ](https://docs-legacy.tigergraph.com)
[Resources](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)
[Developer Site](https://dev.tigergraph.com/) [Community Forum](https://community.tigergraph.com/) [Knowledge Base](https://tigergraph.freshdesk.com/support/solutions)
[Download](https://dl.tigergraph.com)
[ TG Savanna](https://savanna.tgcloud.io)
### [TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
  *     * [Release Notes](https://docs.tigergraph.com/tigergraph-server/3.9/release-notes/)
  *     * [Overview](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
    * [Get Started](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/)
      * Installation
        * [On Docker](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/docker)
        * [On Cloud Marketplace](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/cloud-images/)
          * [AWS](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/cloud-images/aws)
          * [Azure](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/cloud-images/azure)
          * [GCP](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/cloud-images/gcp)
        * [On Linux](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/linux)
          * [System Requirements](https://docs.tigergraph.com/tigergraph-server/3.9/installation/hw-and-sw-requirements)
          * [Linux On Bare Metal](https://docs.tigergraph.com/tigergraph-server/3.9/installation/bare-metal-install)
          * [Post Install Checks](https://docs.tigergraph.com/tigergraph-server/3.9/installation/post-install-check)
        * [Advanced License Issues](https://docs.tigergraph.com/tigergraph-server/3.9/installation/license)
        * [Changing Ports](https://docs.tigergraph.com/tigergraph-server/3.9/installation/change-port)
        * [Upgrade](https://docs.tigergraph.com/tigergraph-server/3.9/installation/upgrade)
        * [Uninstallation](https://docs.tigergraph.com/tigergraph-server/3.9/installation/uninstallation)
      * [The GSQL Shell](https://docs.tigergraph.com/tigergraph-server/3.9/gsql-shell/)
        * [GSQL Shell Sessions](https://docs.tigergraph.com/tigergraph-server/3.9/gsql-shell/gsql-sessions)
        * [Using a Remote GSQL Client](https://docs.tigergraph.com/tigergraph-server/3.9/gsql-shell/using-a-remote-gsql-client)
        * [GSQL Shell (Web)](https://docs.tigergraph.com/tigergraph-server/3.9/gsql-shell/web)
    * [Create Database](https://docs.tigergraph.com/tigergraph-server/3.9/getting-started/database-definition)
      * [MultiGraph Overview](https://docs.tigergraph.com/tigergraph-server/3.9/intro/multigraph-overview)
  *     * [Load Data](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/)
      * [Overview](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/data-loading-overview)
      * [Load from Local Files](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-local-files)
      * [Load from Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)
      * [Load from Data Warehouse](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-warehouse)
      * [Load from External Kafka](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-kafka)
      * [Load DataFrames from Spark](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/spark-connection-via-jdbc-driver)
      * [Manage Data Sources](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/manage-data-source)
      * [Stream from External Kafka (Deprecated)](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/data-streaming-connector/kafka)
  *     * Advanced Topics
      * [System Management](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/management-with-gadmin)
        * [Memory management](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/memory-management)
        * [Manage TigerGraph services](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/manage-services)
        * [Workload Management](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/workload-management)
        * [Metrics Reporting](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/system-metrics)
        * [Command Glossary](https://docs.tigergraph.com/tigergraph-server/3.9/system-management/management-commands)
      * [Access Management](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/)
        * Authentication
          * [Enabling User Authentication](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/enabling-user-authentication)
          * [User Credentials](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/user-credentials)
          * [Single Sign-On](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/sso)
          * [Lightweight Directory Access Protocol (LDAP)](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/ldap)
        * Authorization
          * [User Management](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/user-management)
          * [Role Management](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/role-management)
          * [Access Control Model](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/access-control-model)
          * [Access Control Lists (ACLs)](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/acl-management)
          * [Vertex-Level Access Control (Deprecated)](https://docs.tigergraph.com/tigergraph-server/3.9/user-access/vlac)
      * [Backup and Restore](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/)
        * [Backup and Restore Configurations](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/configurations)
        * [Back up a Database Cluster](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/backup-cluster)
        * [Restore a Database Backup from the Same Cluster](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/restore-backup-same)
        * [Restore a Database Backup from Another Cluster](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/cross-cluster-backup)
        * [Database Import/Export](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/database-import-export)
        * [Legacy Backup and Restore](https://docs.tigergraph.com/tigergraph-server/3.9/backup-and-restore/gbar-legacy)
      * Cluster and HA Management
        * Cluster Resizing
          * [Cluster Expansion](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/expand-a-cluster)
          * [Cluster Shrinking](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/shrink-a-cluster)
          * [Cluster Repartition](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/repartition-a-cluster)
          * [Cluster Replace](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/how_to-replace-a-node-in-a-cluster)
        * [Cross-Region Replication (CRR)](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/crr-index)
          * [Set up CRR](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/set-up-crr)
          * [Fail over to the DR cluster](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/fail-over)
          * [Troubleshooting CRR](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/troubleshooting)
          * [CRR FAQ](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/crr-faq)
        * [High Availability (HA)](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/ha-overview)
          * [Cluster Configuration](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/ha-cluster)
          * [GSQL Server Support](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/ha-for-gsql-server)
          * [Application Server Support](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/ha-for-application-server)
          * [Cluster Commands](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/cluster-commands)
          * [Removal of Failed Nodes](https://docs.tigergraph.com/tigergraph-server/3.9/cluster-and-ha-management/remove-failed-node)
      * [Architecture](https://docs.tigergraph.com/tigergraph-server/3.9/intro/internal-architecture)
        * [MultiGraph Overview](https://docs.tigergraph.com/tigergraph-server/3.9/intro/multigraph-overview)
        * [Transaction Processing and ACID Support](https://docs.tigergraph.com/tigergraph-server/3.9/intro/transaction-and-acid)
        * [Continuous Availability Overview](https://docs.tigergraph.com/tigergraph-server/3.9/intro/continuous-availability-overview)
      * [Kubernetes (Preview)](https://docs.tigergraph.com/tigergraph-server/3.9/kubernetes/)
        * [Kubernetes Operator (Preview)](https://docs.tigergraph.com/tigergraph-server/3.9/kubernetes/k8s-operator/)
  *     * [Security](https://docs.tigergraph.com/tigergraph-server/3.9/security/)
      * [Auditing Privileged User Actions](https://docs.tigergraph.com/tigergraph-server/3.9/security/audit-privileged-actions)
      * [Encrypting Connections](https://docs.tigergraph.com/tigergraph-server/3.9/security/encrypting-connections)
      * [Encrypting Data At Rest](https://docs.tigergraph.com/tigergraph-server/3.9/security/encrypting-data-at-rest)
      * [File Output Policy](https://docs.tigergraph.com/tigergraph-server/3.9/security/file-output-policy)
      * [Configuring Login Protection](https://docs.tigergraph.com/tigergraph-server/3.9/security/login-protection)
  *     * [REST API Reference](https://docs.tigergraph.com/tigergraph-server/3.9/API/)
      * [Authentication](https://docs.tigergraph.com/tigergraph-server/3.9/API/authentication)
      * [Built-in Endpoints](https://docs.tigergraph.com/tigergraph-server/3.9/API/built-in-endpoints)
      * [Built-in Endpoints JSON Catalog](https://docs.tigergraph.com/tigergraph-server/3.9/API/json-catalog)
      * [Upsert data to graph](https://docs.tigergraph.com/tigergraph-server/3.9/API/upsert-rest)
  *     * Additional Resources
      * Troubleshooting and FAQs
        * [Knowledge base and FAQs](https://kb.tigergraph.com/)
        * [System Administration FAQs](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/system-administration-faqs)
        * [Log Files](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/log-files)
          * [Gathering Log Information with gcollect](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/gcollect)
          * [Audit Logs](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/audit-logs)
          * [Set up Log Viewing with Elasticsearch, Kibana and Filebeat](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/elk-filebeat)
        * [Troubleshooting Guide](https://docs.tigergraph.com/tigergraph-server/3.9/troubleshooting/troubleshooting-guide)
      * References
        * [Configuration Parameters](https://docs.tigergraph.com/tigergraph-server/3.9/reference/configuration-parameters)
        * [Return codes](https://docs.tigergraph.com/tigergraph-server/3.9/reference/return-codes)
        * [List of Privileges](https://docs.tigergraph.com/tigergraph-server/3.9/reference/list-of-privileges)
        * [List of Ports](https://docs.tigergraph.com/tigergraph-server/3.9/reference/ports)
        * [Glossary](https://docs.tigergraph.com/tigergraph-server/3.9/reference/glossary)
        * [Patents and Third Party Software](https://docs.tigergraph.com/tigergraph-server/3.9/reference/patents-and-third-party-software)
        * [Legacy Version Documentation](https://docs.tigergraph.com/tigergraph-server/3.9/additional-resources/legacy-tg-versions)
        * [Comparing TigerGraph Editions](https://docs.tigergraph.com/tigergraph-server/3.9/intro/comparison-of-editions)
        * [Release and Patch Process](https://docs.tigergraph.com/tigergraph-server/3.9/intro/release-process)


TigerGraph DB 3.9
[Fully-Managed: Savanna](https://docs.tigergraph.com/savanna/main/overview/)
[Self-Managed: TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
[Install](https://docs.tigergraph.com/tigergraph-server/current/getting-started/) [Manage](https://docs.tigergraph.com/tigergraph-server/current/system-management/)
Tutorials & Guides
[GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/GSQL.md) [OpenCypher in GSQL](https://github.com/tigergraph/ecosys/blob/master/tutorials/Cypher.md) [Hybrid Vector Search](https://github.com/tigergraph/ecosys/blob/master/tutorials/VectorSearch.md)
Reference Manuals
[GSQL](https://docs.tigergraph.com/gsql-ref/4.2/intro/) [OpenCypher](https://docs.tigergraph.com/gsql-ref/current/opencypher-in-gsql/) [Vector](https://docs.tigergraph.com/gsql-ref/current/vector/) [REST APIs](https://docs.tigergraph.com/tigergraph-server/current/api/) [Configuration Parameters](https://docs.tigergraph.com/tigergraph-server/current/reference/configuration-parameters)
Visual Tools
[Develop: GraphStudio](https://docs.tigergraph.com/gui/4.2/intro/) [Administer: Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/) [Visualize: Insights](https://docs.tigergraph.com/insights/4.2/intro/)
AI & Data Science
[Graph Algorithms](https://docs.tigergraph.com/graph-ml/3.10/intro/) [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/) [TigerGraphX](https://github.com/tigergraph/ecosys/blob/master/tutorials/TigerGraphX.md) [ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/) [CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph DB](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/tigergraph-server/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/tigergraph-server/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/tigergraph-server/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/tigergraph-server/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/tigergraph-server/3.6/intro/)
  * [GSQL Language Reference](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gsql-ref/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gsql-ref/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gsql-ref/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gsql-ref/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gsql-ref/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gsql-ref/3.6/intro/intro)
  * [TigerGraph Savanna](https://docs.tigergraph.com/savanna/main/overview/)
  * [GraphStudio and Admin Portal](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/gui/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/gui/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/gui/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/gui/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/gui/3.9/intro/)
    * [3.6](https://docs.tigergraph.com/gui/3.6/graphstudio/overview)
  * [Insights](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.2 Pre](https://docs.tigergraph.com/insights/4.2/intro/)
    * [4.1](https://docs.tigergraph.com/insights/4.1/intro/)
    * [3.11](https://docs.tigergraph.com/insights/3.11/intro/)
    * [3.10](https://docs.tigergraph.com/insights/3.10/intro/)
    * [3.9](https://docs.tigergraph.com/insights/3.9/intro/)
  * [Graph Data Science Library](https://docs.tigergraph.com/graph-ml/3.10/intro/)
    * [3.10](https://docs.tigergraph.com/graph-ml/3.10/intro/)
  * [pyTigerGraph](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.8](https://docs.tigergraph.com/pytigergraph/1.8/intro/)
    * [1.7](https://docs.tigergraph.com/pytigergraph/1.7/intro/)
    * [1.6](https://docs.tigergraph.com/pytigergraph/1.6/intro/)
  * [TigerGraph ML Workbench](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
    * [1.4](https://docs.tigergraph.com/ml-workbench/1.4/intro/)
  * [TigerGraph GraphQL Service](https://docs.tigergraph.com/graphql/3.9/)
    * [3.9](https://docs.tigergraph.com/graphql/3.9/)
  * [TigerGraph CoPilot](https://docs.tigergraph.com/tg-copilot/intro/)
    * [main](https://docs.tigergraph.com/tg-copilot/intro/)
  * [TigerGraph Cloud Classic](https://docs.tigergraph.com/cloud/main/start/overview)


[](https://docs.tigergraph.com/home/)
  * [TigerGraph DB 3.9](https://docs.tigergraph.com/tigergraph-server/3.9/intro/)
  * [Load Data](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/)
  * [Load from Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud)


[Edit this Page](https://github.com/tigergraph/server-docs/edit/3.9/modules/data-loading/pages/load-from-cloud.adoc)
### Contents
  * [Example Schema](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_schema)
  * [Create Data Source Object](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_data_source_object)
  * [AWS S3](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_aws_s3)
  * [Azure Blob Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_azure_blob_storage)
  * [Google Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_google_cloud_storage)
  * [Create a loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_a_loading_job)
  * [Example loading job from cloud storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_loading_job_from_cloud_storage)
  * [Define filenames](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_define_filenames)
  * [Specify the data mapping](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_specify_the_data_mapping)
  * [Run the loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_run_the_loading_job)
  * [Continuous Loading from Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_continuous_loading_from_cloud_storage)
  * [Manage and monitor your loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_and_monitor_your_loading_job)
  * [Manage loading job concurrency](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_loading_job_concurrency)
  * [Known Issues with Loading](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_known_issues_with_loading)


# Load from Cloud Storage
Table of Contents
  * [Example Schema](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_schema)
  * [Create Data Source Object](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_data_source_object)
    * [AWS S3](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_aws_s3)
    * [Azure Blob Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_azure_blob_storage)
    * [Google Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_google_cloud_storage)
  * [Create a loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_a_loading_job)
    * [Example loading job from cloud storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_loading_job_from_cloud_storage)
    * [Define filenames](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_define_filenames)
      * [Cloud file descriptors](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_cloud_file_descriptors)
      * [Filename parameters](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_filename_parameters)
    * [Specify the data mapping](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_specify_the_data_mapping)
  * [Run the loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_run_the_loading_job)
    * [Continuous Loading from Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_continuous_loading_from_cloud_storage)
  * [Manage and monitor your loading job](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_and_monitor_your_loading_job)
  * [Manage loading job concurrency](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_loading_job_concurrency)
  * [Known Issues with Loading](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_known_issues_with_loading)


After you have [defined a graph schema](https://docs.tigergraph.com/gsql-ref/3.9/ddl-and-loading/defining-a-graph-schema), you can create a loading job, specify your data sources, and run the job to load data.
The steps are similar whether you are loading from local files, from cloud storage, or any of the other supported sources. We will call out whether a particular step is common for all loading or specific to a data source or loading mode.
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_schema)Example Schema
This example uses part of the LDBC_SNB schema:
Example schema taken from LDBC_SNB
```
//Vertex Types:
CREATE VERTEX Person(PRIMARY_ID id UINT, firstName STRING, lastName STRING,
 gender STRING, birthday DATETIME, creationDate DATETIME, locationIP STRING,
 browserUsed STRING, speaks SET<STRING>, email SET<STRING>)
 WITH STATS="OUTDEGREE_BY_EDGETYPE", PRIMARY_ID_AS_ATTRIBUTE="true"
CREATE VERTEX Comment(PRIMARY_ID id UINT, creationDate DATETIME,
 locationIP STRING, browserUsed STRING, content STRING, length UINT)
 WITH STATS="OUTDEGREE_BY_EDGETYPE", PRIMARY_ID_AS_ATTRIBUTE="true"
//Edge Types:
CREATE DIRECTED EDGE HAS_CREATOR(FROM Comment, TO Person)
 WITH REVERSE_EDGE="HAS_CREATOR_REVERSE"
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_data_source_object)Create Data Source Object
A data source code provides a standard interface for all supported data source types, so that loading jobs can be written without regard for the data source.
When you create the object, you specify its details (type, access credentials, etc.) in the form of a JSON object. The JSON object can either be read in from a file or provided inline. Inline mode is required when creating data sources for TigerGraph Cloud instances.
In the following example, we create a data source named `s1`, and read its configuration information from a file called `ds_config.json`.
```
USE GRAPH ldbc_snb
CREATE DATA_SOURCE s1 = "ds_config.json" FOR GRAPH ldbc_snb
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Older versions of TigerGraph required a keyword after `DATA_SOURCE` such as `STREAM` or `KAFKA`.
Inline JSON data format when creating a data source
```
CREATE DATA_SOURCE s1 = "{
type: <type>,
key: <value>
}" FOR GRAPH ldbc_snb
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

String literals can be enclosed with a double quote `"`, triple double quotes `"""`, or triple single quotes `'''`. Double quotes `"` in the JSON can be omitted if the key name does not contain a colon `:` or comma `,`.
Alternate quote syntax for inline JSON data
```
CREATE DATA_SOURCE s1 = """{
"type": "<type>",
"key": "<value>"
}""" FOR GRAPH ldbc_snb
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Key names accept a separator of either a period `.` or underscore `_`, so for example, `key_name` and `key.name` are both valid key names.
Three cloud source types are supported:
  * [Amazon S3](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_aws_s3)
  * [Azure Blob Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_azure_blob_storage)
  * [Google Cloud Storage](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_google_cloud_storage)


Also, three data object formats are supported: CSV, JSON, and Parquet.
### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_aws_s3)AWS S3
The connector offers two methods for authentication:
  * The standard IAM credential provider using your access key
  * AWS Identity and Access Management (IAM) role associated with the EC2 instance


Access keys can be used for an individual user or for an IAM role. For the access key method, include the following fields in the data source connection:
```
{
 "type": "s3",
 "access.key": "<access key>",
 "secret.key": "<secret key>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For the IAM role method, you must attach an IAM role to all the EC2 instances which constitute your TigerGraph database cluster. Include the following fields in the data source connection:
```
{
 "type": "s3",
 "file.reader.settings.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.InstanceProfileCredentialsProvider",
 "access.key": "none",
 "secret.key": "none"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For more information, see Amazon documentation on using IAM roles for Amazon EC2.
**Temporary Credentials**
In addition, AWS temporary credentials are supported. A temporary credential can be generated from the AWS CLI. For example:
```
aws sts assume-role --role-arn arn:aws:iam::<account-id>:role/<role> --role-session-name "<session-name>"
bash![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For more details on temporary credentials, please refer to AWS documentation on [temporary security credentials in IAM](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html).
To use the temporary credential, add the below configurations in the data source definition:
```
{
  "type": "s3",
  "file.reader.settings.fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider",
  "access.key": "The <AccessKeyId> in credential",
  "secret.key": "The <SecretAccessKey> in credential",
  "file.reader.settings.fs.s3a.session.token": "The <SessionToken> in credential"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Example temporary credential from AWS
```
{
  "Credentials": {
    "AccessKeyId": "ASIA...X4M3A",
    "SecretAccessKey": "/wSVO...WUZYv0",
    "SessionToken": "IQoJb3J...O1k=",
    "Expiration": "2024-10-10T23:00:00+00:00"
  },
  "AssumedRoleUser": {
    "AssumedRoleId": "A...1",
    "Arn": "arn:aws:sts::<acount>:assumed-role/<role-name>/<session-name>"
  }
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_azure_blob_storage)Azure Blob Storage
The connector supports two types of authentication:
**Shared key authentication** :
Get the account key on the Access Keys tab of your storage account. TigerGraph can automatically extract the account name from the file URI, so there’s no need to provide the account name.
```
{
  "type" : "abs",
  "account.key" : "<account key>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

![Azure Access Keys tab](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/_images/azure-storage-account.png)
**Service principal authentication** :
To use service principal authentication, you must first register your TigerGraph instance as an application and grant it access to your storage account.
```
{
  "type" : "abs",
  "client.id" : "<client id>",
  "client.secret" : "<client secrect>",
  "tenant.id" : "<tenant id>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_google_cloud_storage)Google Cloud Storage
For GCS, the TigerGraph data source configuration object is based on the _GCS service account key_ format.
```
{
  "type": "gcs",
  "project_id": "<project id>",
  "private_key_id": "<private key id>",
  "private_key": "<private key>",
  "client_email": "<email address>"
}
json![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

You can follow Google Cloud’s instructions for creating a service account key, and then replace the `"type"` value with `"gcs"`.
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_create_a_loading_job)Create a loading job
A loading job tells the database how to construct vertices and edges from data sources. The loading job body has two parts:
  1. DEFINE statements create variables to refer to data sources. These can refer to actual files or be placeholder names. The actual data sources can be given when running the loading job.
  2. LOAD statements specify how to take the data fields from files to construct vertices or edges.


### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_example_loading_job_from_cloud_storage)Example loading job from cloud storage
The following example uses AWS S3 as the source.
Example loading job from cloud storage
```
USE GRAPH ldbc_snb
CREATE LOADING JOB load_data FOR GRAPH ldbc_snb {
 DEFINE FILENAME file_Comment =
  "$s1:s3://s3-loading-test/tg_ldbc_snb/sf0.1_csv/dynamic/Comment";
 DEFINE FILENAME file_Person =
  "$s1:s3://s3-loading-test/tg_ldbc_snb/sf0.1_csv/dynamic/Person";
 DEFINE FILENAME file_Comment_hasCreator_Person =
  "$s1:s3://s3-loading-test/tg_ldbc_snb/sf0.1_csv/dynamic/Comment_hasCreator_Person";
 LOAD file_Comment
  TO VERTEX Comment
   VALUES ($1, $0, $2, $3, $4, $5) USING header="true", separator="|";
 LOAD file_Person
  TO VERTEX Person
   VALUES ($1, $2, $3, $4, $5, $0, $6, $7, SPLIT($8,";"), SPLIT($9,";"))
   USING header="true", separator="|";
 LOAD file_Comment_hasCreator_Person
  TO EDGE HAS_CREATOR
   VALUES ($1, $2) USING header="true", separator="|";
}
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_define_filenames)Define filenames
First we define _filenames_ , which are local variables referring to data files (or data objects).
The terms `FILENAME` and `filevar` are used for legacy reasons, but a `filevar` can also be an object in a data object store.   
---  
DEFINE FILENAME syntax
```
DEFINE FILENAME filevar ["=" file_descriptor ];
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

The file descriptor can be specified at compile time or at runtime. Runtime settings override compile-time settings:
Specifying file descriptor at runtime
```
RUN LOADING JOB job_name USING filevar=file_descriptor_override
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

While a loading job may have multiple `FILENAME` variables , they must all refer to the same `DATA_SOURCE` object.   
---  
#### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_cloud_file_descriptors)Cloud file descriptors
For cloud sources, the file descriptor has three valid formats. You can simply provide the file URI. Or, you can provide optional configuration details, either in a JSON file or as inline JSON content.
```
DEFINE FILENAME file_name = "$[data source name]:[URI]";
DEFINE FILENAME file_name = "$[data source name]:[json config file]";
DEFINE FILENAME file_name = "$[data source name]:[inline json content]";
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

See the following examples.
```
// Format 1: URI only
DEFINE FILENAME uri_s3 = "$s_s3:s3://s3-loading-test/tg_ldbc_snb/sf0.1_csv/dynamic/Comment";
DEFINE FILENAME uri_gcs = "$s_gcs:gs://tg_ldbc_snb/sf0.1_csv/dynamic/Person";
DEFINE FILENAME uri_abs = "$s_abs:abfss://person@yandblobstorage.dfs.core.windows.net/persondata.csv";
// Format 2: URI and configuration file
DEFINE FILENAME uri_s3 = "$s1:myfile.json";
// Format 3: URI and inline JSON
DEFINE FILENAME parquet_s3 = """$s1:{
 "file.uris":"s3://s3-loading-test/tg_ldbc_snb/sf0.1_parquet/dynamic/Comment",
 "file.type":"parquet"}""";
DEFINE FILENAME csv_gcs = """$s1:{
 "file.uris": "gs://tg_ldbc_snb/sf0.1_csv/dynamic/Person",
 "file.type": "text",
 "num.partitions": 6}""";
go![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

#### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_filename_parameters)Filename parameters
These are the required and optional configuration parameters:
Parameter | Description | Required? | Default value  
---|---|---|---  
file.uris | The URI or URIs separated by commas. | Required | N/A  
file.type | `text` for CSV and JSON files; `parquet` for Parquet files. | Optional | If the file extension is `parquet`, then file.type default is Parquet; otherwise the default is `text`.  
num.partitions | The number of partitions to use. When loading data, each partition is distributed evenly across each node. If one filename contains much more data than others, consider using a larger partition number. | Optional | 3  
batch.size | The number of CSV lines or JSON objects that will be processed per batch. | Optional | 10000  
recursive | If the URI refers to a directory, whether to search subdirectories recursively for files to load. | Optional | true  
regexp | A regular expression to filter filenames to be loaded. Uses Java regular expression patterns. | Optional | .*, which permits all filenames.  
default | The default value for any field left empty. | Optional | "", an empty string.  
archive.type | The file type for archive files. Accepted values: `auto` (where it uses the file extension as the file type), `tar`, `zip`, `gzip`, `tar.gz` and `none` (loading from an uncompressed file). | Optional | auto  
tasks.max | The number of threads used to download data. | Optional | 1  
### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_specify_the_data_mapping)Specify the data mapping
Next, we use LOAD statements to describe how the incoming data will be loaded to attributes of vertices and edges. Each LOAD statement handles the data mapping, and optional data transformation and filtering, from one filename to one or more vertex and edge types.
LOAD statement syntax
```
LOAD [ source_object|filevar|TEMP_TABLE table_name ]
 destination_clause [, destination_clause ]*
 [ TAGS clause ] **(1)**
 [ USING clause ];
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

**1** | As of v3.9.3, TAGS are deprecated.  
---|---  
Let’s break down one of the LOAD statements in our example:
Example loading job for local files
```
LOAD file_Person TO VERTEX Person
  VALUES($1, $2, $3, $4, $5, $0, $6, $7,
    SPLIT($8, ";"), SPLIT($9, ";"))
  USING SEPARATOR="|", HEADER="true", EOL="\n";
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

  * `$0`, `$1`,…​ refer to the first, second, …​ columns in each line a data file.
  * `SEPARATOR="|"` says the column separator character is the pipe (`|`). The default is comma (`,`).
  * `HEADER="true"` says that the first line in the source contains column header names instead of data. These names can be used instead of the columnn numbers.
  * `SPLIT` is one of GSQL’s ETL functions. It says that there is a multi-valued column, which has a separator character to mark the subfields in that column.


Refer to [Creating a Loading Job](https://docs.tigergraph.com/gsql-ref/3.9/ddl-and-loading/creating-a-loading-job) in the GSQL Language Reference for descriptions of all the options for loading jobs.
When loading JSON or Parquet data, please make sure:
  * The USING option JSON_FILE="true" is used
  * Refer to JSON keys (≈ Parquet "column names") instead of column indices.

E.g., `LOAD file_Comment TO VERTEX Comment VALUES ($"id", $"content") USING JSON_FILE="TRUE"`  
---  
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_run_the_loading_job)Run the loading job
Use the command `RUN LOADING JOB` to run the loading job.
RUN LOADING JOB basic syntax (some options omitted)
```
RUN LOADING JOB [-noprint] job_name [
 USING filevar [="file_descriptor"][, filevar [="file_descriptor"]]*
 [,EOF="eof_mode"]
]
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

**-noprint**
By default, the loading job will run in the foreground and print the loading status and statistics after you submit the job. If the `-noprint` option is specified, the job will run in the background after displaying the job ID and the location of the log file.
**filevar list**
The optional `USING` clause may contain a list of file variables. Each file variable may optionally be assigned a `file_descriptor`, obeying the same format as in `CREATE LOADING JOB`. This list of file variables determines which parts of a loading job are run and what data files are used.
When a loading job is compiled, it generates one RESTPP endpoint for each `filevar` and source_object. As a consequence, a loading job can be run in parts. When `RUN LOADING JOB` is executed, only those endpoints whose filevar or file identifier (`_GSQL_FILENAME_n_`) is mentioned in the`USING` clause will be used. However, if the `USING` clause is omitted, then the entire loading job will be run.
If a `file_descriptor` is given, it overrides the `file_descriptor` defined in the loading job. If a particular `filevar` is not assigned a `file_descriptor` either in the loading job or in the `RUN LOADING JOB` statement, an error is reported and the job exits.
### [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_continuous_loading_from_cloud_storage)Continuous Loading from Cloud Storage
`EOF` (End-of-file) is a boolean parameter. The loader has two modes: streaming mode ("False") and EOF mode ("True").
Prior to version 3.9.2, the default value of `EOF` was "False". Beginning with 3.9.2, the default value is "True".
  * If `EOF` = "True" (EOF mode), loading will stop after consuming the provided file objects, i.e, when it reaches the `EOF` character for each file object.
  * If `EOF` = "False" (streaming mode), the loading job remains active and keeps for new data until the job is aborted. The loader can detect both new lines in existing files and new files added to the designated source folder.


Streaming mode checks for new content based on _increased line number_. Only new lines in existing files and new files will be loaded. If any existing lines are changed or deleted, these changes will not be part of the loading job.   
---  
For example, consider a file `data.txt` in cloud storage
Initial state of `data.txt`
```
line-1
txt![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

1) We load `data.txt` using streaming mode.
```
RUN LOADING JOB stream_csv USING EOF="false"
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

The line of data is loaded successfully into the loading job for ingestion to TigerGraph.
2) If a user edits the file and adds a new line, the stream loader notices the addition and loads the new line, starting from where it previously left off.
`data.txt` after a line is added
```
line-1
line-2
txt![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

In this case, the new line `line-2` is successfully ingested to TigerGraph,for a total of two lines.
3) If a user edits the file and inserts a line _before_ the end, as shown below, the entire file is loaded again.
data.txt after a new line is added before the end
```
line-1
added-line
line-2
txt![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

Because two lines had already been loaded, the first two lines are skipped, even though the second contains new data. The third line from the file is then loaded, resulting in a repeat of `line-2`.
Data in TigerGraph
```
line-1
line-2
line-2
txt![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

To insure data is loaded correctly, only use stream mode when there is no chance of data being altered or added to the middle of a file.   
---  
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_and_monitor_your_loading_job)Manage and monitor your loading job
When a loading job starts, the GSQL server assigns it a job ID and displays it for the user to see. There are three key commands to monitor and manage loading jobs:
```
SHOW LOADING STATUS job_id|ALL
ABORT LOADING JOB job_id|ALL
RESUME LOADING JOB job_id
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

`SHOW LOADING STATUS` shows the current status of either a specified loading job or all current jobs, this command should be within the scope of a graph:
```
GSQL > USE GRAPH graph_name
GSQL > SHOW LOADING STATUS ALL
php![copy icon](https://docs.tigergraph.com/_/img/octicons-16.svg#view-clippy)Copied!

```

For each loading job, the above command reports the following information:
  * Loading status
  * Loaded lines/Loaded objects/Error lines
  * Average loading speed
  * Size of loaded data
  * Duration


When inspecting all current jobs with `SHOW LOADING STATUS ALL`, the jobs in the `FINISHED` state will be omitted as they are considered to have successfully finished. You can use `SHOW LOADING STATUS job_id` to check the historical information of finished jobs.
See [Managing and Inspecting a Loading Job](https://docs.tigergraph.com/gsql-ref/3.9/ddl-and-loading/managing-loading-job) for more details.
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_manage_loading_job_concurrency)Manage loading job concurrency
See [Loading Job Concurrency](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/loading-concurrency) for how to manage the concurrency of loading jobs.
## [](https://docs.tigergraph.com/tigergraph-server/3.9/data-loading/load-from-cloud#_known_issues_with_loading)Known Issues with Loading
TigerGraph does not store NULL values. Therefore, your input data should not contain any NULLs.   
---  
[3.9.2+] If the connector is manually deleted before reaching EOF, the corresponding loading job will never stop. Please use ABORT LOADING JOB to terminate the loading pipeline instead of directly manipulating the connector.
3 Twin Dolphin Drive, Ste 225 Redwood City, CA 94065 
Copyright © 2025 TigerGraph
  * ## Resources
    * [Support](https://www.tigergraph.com/support/)
    * [Community](https://community.tigergraph.com/)
    * [Developer Site](https://dev.tigergraph.com/)
    * [Test Drive](https://testdrive.tigergraph.com/)
  * ## Social
    * [Linkedin](https://www.linkedin.com/company/tigergraph/)
    * [Facebook](https://www.facebook.com/TigerGraphDB/)
    * [Twitter](https://twitter.com/tigergraphdb)
  * ## Legal
    * [Privacy Policy](https://www.tigergraph.com/privacy-policy/)
    * [Terms of Use](https://www.tigergraph.com/terms/)
    * [Sitemap](https://docs.tigergraph.com/sitemap.xml)


